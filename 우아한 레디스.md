# 개요

### 다루지 않는 것들 
* Redis Persistence (RDB, AOF)   
* Redis Pub/Sub
* Redis  Stream
* 확률적 자료구조  
  * Hyperloglog
* Redis Module

### 추가 도움 
https://codingmania.tistory.com/18   

# Redis 소개      
* In-Memory Data Structure Store (메모리 기반의 데이터 저장소)       
* Open Source(BSD 3 License) (코드를 고치고 숨겨도 상관 없다)      
* Support data structures (서포팅 하는 자료구조)
  * Stirngs, set, sorted-set, hashes, list   
  * Hyperloglog, bitmap, geospatial index   
  * stream   
* Only 1 Commiter (레디스 소스 코드를 고칠 수 있는 사람은 전세계 단 1명이다)             
      
디스크가 아닌 메모리 기반의 데이터 저장소이다.      
```BSD 3 License``` 이기 때문에 코드를 고치고 숨겨도 상관 없고 사용한다는 명시만 해주면 된다.         
단, Redis 모듈은 라이센스가 틀리기 때문에 코드를 고치면 공개해야한다.    

## Redis 를 소개하기 전에 Cache 먼저     
Cache : 나중에 요청될 결과를 미리 저장해두었다가 빠르게 서비스를 해주는 것을 의미       
    
**Factorial 계산** 
* 10! = ```10*9!``` = ```10 * 9 * 8!``` = ```10 * 9 * 8 * 7!```= ....   
* 팩토리얼 숫자가 크다면?     
  * 이전 팩토리얼 계산을 계속해주어야 하나?    
  **DP의 메모라이제이션처럼 기존에 데이터를 저장해두고 이를 다시 연산하지 말고 사용하자는 개념 적용한다.**             
     
그리고 위의 개념처럼 다시 연산하지 말고 사용하는 개념이 **Cache의 목적**이기도 하다.    
접근 속도가 다르기 때문이라는데 이는 깊게 들어가지 않고 바로 계산하기 때문이라는 말 같다.   
   
## CPU Cache     
![cpu cache](https://user-images.githubusercontent.com/50267433/92561548-5e173800-f2af-11ea-98b8-56b5cd413010.PNG)    

* 용량이 커질수록 속도는 빨라진다. -> 반비례 구조       
* Disk가 가장 느리고 CPU의 Registry(core)가 가장 빠르다.       
* 참고로 우리가 일반적으로 말하고 사용하는 Registry 는 Memory에 있는것이다. (즉 cpu와 별개)   
* **Disk 접근 속도는 SSD를 사용하더라도 메모리에 비하면 큰 차이가 난다 -> 메모리에 올려놓고 사용하는게 Disk 보다 빠름**  
* 대신 용량은 당연 Disk가 많다.      

## 어디서 많이 사용하나요?  
### 아주 추상적인 웹서비스 구조       
![어디서 사용](https://user-images.githubusercontent.com/50267433/92562028-41c7cb00-f2b0-11ea-8b0b-b30d907f755b.PNG)     
DB 안에는 많은 데이터들이 있고, 이때 주로 디스크에 내용이 저장되게 됩니다.    
           
클라이언트가 웹서버(WAS)에 접속하고 웹 서버가 다시 DB의 데이터를 가져온다.            
DB도 내부적으로 Cache를 사용하는데 메모리 사이즈보다 크면 디스크를 사용한다.       
DB도 자기가 쿼리 연결되면 Cache의 내부적인 Cache에 담고 있는데      
여러가지를 계속 접근하다 보면 기존에 있던 Cache를 날리고 Disk에서 새로 읽어야한다.      
그래서 Disk 접근을 할때마다 속도가 느릴 수 있다.     

### 파레토의 법칙     
모든것의 80% 는 사용자의 20%가 결정한다.       
이는 웹 서비스에서도 마찬가지로 **전체 요청의 80% 는 20%의 사용자**          
그렇기 때문에 Caching 을 좀더 적은 메모리로 효율적으로 처리할 수 있다.         

### Cache 구조 1 - Look aside Cache : 일반적인 방법   
![일반적인 캐시사용](https://user-images.githubusercontent.com/50267433/92562652-4771e080-f2b1-11ea-91b1-0466f0137d4c.PNG)    
    
1. WebService 는 데이터가 존재하는지 Cache 를 연계 확인     
2. Cache 에 데이터가 있으면 Cache 에서 가져온다.     
3. Cache에 데이터가 없다면 DB에서 불러온다.      
4. DB에서 불러온 데이터를 다시 Cache에 저장한다.      

### Cache 구조 2 - Write Back : 다른 방법 

1. WebService 는 모든 데이터를 Cache 에만 저장 
2. Cache 에 특정 시간동안의 데이터가 저장  
3. Cache에 있는 데이터를 DB에 저장한다.   
4. DB에 저장된 데이터를 삭제한다.     
           
디스크 기반 DB라 치면 그것을 무조건 DB에 저장해야한다.             
하지만 그런것들을 일단 Cache에 일단 저장했다가 특정 시점마다 DB에 저장하는 방법이다.                
예를 들면 ```INSERT``` 1개를 500번 날리는게 아니고 Cache에 저장했다가 1번에 500개를 쓰는 형태이다.            
**위 말을 다시 해석하자면 안그래도 느린 Disk 방식에서 1개의 쿼리를 500번 날리는 것은 매우 비효율적이다.**     
       
하지만 단점도 존재하는데              
캐시는 메모리니까 리부팅 되거나 장애가 발생하면 데이터가 사라질 가능성이 존재합니다.          
  
# 왜 Collection 중요한가?    
Memcached 는 Collection을 제공하지 않지만 Redis 는 Collection을 제공합니다.        
왜 Collection이 좋나요?         
   
* 개발의 편의성 증가          
* 개발의 난이도 감소       
  
Collection은 이미 만들어진 라이브러리 같은 것으로    
Memcached 는 비슷한 기능을 사용하기 위해 이것저것 건드리지만 Redis는 그렇지 않다.     
마치 Python 처럼 기본 제공된 기능과 많은 라이브러리로 인해 생산성이 높다고 말하는 것과 같다.     
   
## 개발의 편의성         
**랭킹 서버를 직접 구현한다면?**       
       
* 가장 간단한 방법 :       
  * DB에 유저의 Score를 저장하고 Score로 Order By 정렬 후 읽어오기           
  * 개수가 많아지면 속도에 문제가 발생할 수 있습니다.          
  즉, 데이터 사용자가 많으면 제대로 동작을 안한다. (속도가 느리다)          
  ■ 그리고 데이터가 많아지면 결국은 디스크를 사용하게 되므로 느려질 수 밖에 없다.             

그렇기 때문에 Disk 를 사용하는 것이 아닌 In-Memory 기준으로 구현이 필요하다.   
   
* In-Memory 기준으로 랭킹 서버의 구현이 필요함   
* Redis의 Sorted Set을 이용하면, 랭킹을 구현할 수 있습니다.   
  * 덤으로 Repliaction 도 가능...
  * 다만 가져다 쓰면 거기의 한계에 종속적이게 됩니다.    
  * 랭킹에 저장해야할 ID가 1개당 100Byte라고 했을 때   
    * 10 명 1K
    * 10000명 1M
    * 10000000명 1G
    * 10000000000명 1TB

# Redis Collections   
# Redis 운영 
# Redis 데이터 분산 
# Redis Failover  
